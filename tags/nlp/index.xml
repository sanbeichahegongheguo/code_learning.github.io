<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nlp on 火山灰</title>
    <link>https://sanbeichahegongheguo.github.io/tags/nlp/</link>
    <description>Recent content in Nlp on 火山灰</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://sanbeichahegongheguo.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>自然语言处理入门</title>
      <link>https://sanbeichahegongheguo.github.io/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sanbeichahegongheguo.github.io/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8/</guid>
      <description>一、文本相似度计算 文本相似度计算在信息检索、数据挖掘、机器翻译、文档复制检测等领域有着广泛的应用。文本相似度常用的计算方法有TF-IDF、LSI、LDA等。
TF-IDF模型 TF-IDF（Term Frequency-Inverse Document Frequency）是一种统计方法，用以评估某一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。
 字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。
 TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。
在一份给定的文件里，词频 (term frequency, TF) 指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被归一化，以防止它偏向长的文件。
逆向文件频率 (inverse document frequency, IDF) 是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。
某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。
TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。
LSI模型 LSI（Latent Semantic Indexing）又称为潜在语义分析(LSA)，是在信息检索领域提出来的一个概 念。主要用于解决一词多义（如“bank”一词，可以指银行，也可以指河岸）和一义多词（如“car”和“automobile”具有相同的含义）。依靠余弦相似性的方法并不能很好地解决上述问题，所以提出了潜在语义索引的方法，利用SVD降维的方法将词项和文本映射到一个新的空间。
LDA模型 LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布。
LDA是一种非监督机器学习技术，可以用来识别大规模文档集（document collection）或语料库（corpus）中潜藏的主题信息。它采用了词袋（bag of words）的方法，这种方法将每一篇文档视为一个词频向量，从而将文本信息转化为了易于建模的数字信息。但是词袋方法没有考虑词与词之间的顺序，这简化了问题的复杂性，同时也为模型的改进提供了契机。每一篇文档代表了一些主题所构成的一个概率分布，而每一个主题又代表了很多单词所构成的一个概率分布。
二、中文文本处理利器snownlp SnowNLP是一个python写的类库，可以方便的处理中文文本内容。如中文分词、词性标注、情感分析、文本分类、提取文本关键词、文本相似度计算等。
snownlp示例如下所示：
# -*- coding: utf-8 -*- &amp;quot;&amp;quot;&amp;quot; Created on Wed May 31 22:28:23 2017 @author: Administrator &amp;quot;&amp;quot;&amp;quot; from snownlp import SnowNLP s = SnowNLP(u&#39;这个东西真心很赞&#39;) s.words # [u&#39;这个&#39;, u&#39;东西&#39;, u&#39;真心&#39;, # u&#39;很&#39;, u&#39;赞&#39;] s.</description>
    </item>
    
  </channel>
</rss>