<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>转载 | 自然语言处理入门 - 个人随想</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="总舵主"><meta name=description content="先整理一些资料。
"><meta name=generator content="Hugo 0.81.0"><link rel=canonical href=/post/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="转载 | 自然语言处理入门"><meta property="og:description" content="先整理一些资料。"><meta property="og:type" content="article"><meta property="og:url" content="/post/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8/"><meta property="article:section" content="post"><meta property="og:site_name" content="个人随想"><meta itemprop=name content="转载 | 自然语言处理入门"><meta itemprop=description content="先整理一些资料。"><meta itemprop=wordCount content="11948"><meta itemprop=keywords content="编程,NLP,入门,转载,python,"><meta name=twitter:card content="summary"><meta name=twitter:title content="转载 | 自然语言处理入门"><meta name=twitter:description content="先整理一些资料。"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>火山灰</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=/>首页</a></li><li class=mobile-menu-item><a class=menu-item-link href=/post/>时间轴</a></li><li class=mobile-menu-item><a class=menu-item-link href=/tags/>标签</a></li><li class=mobile-menu-item><a class=menu-item-link href=/categories/>归档</a></li><li class=mobile-menu-item><a class=menu-item-link href=/about/>About</a></li><li class=mobile-menu-item><div class="mobile-menu-parent mobile-menu-item-lang"><span class=mobile-submenu-open></span><a href=#><i class=iconfont>&lt;?xml version="1.0" standalone="no"?><!doctype html><svg width="100%" height="100%" xmlns="http://www.w3.org/2000/svg"><path d="M153 334s-2 0-2 0c0 5 2 10 5 10 8 0 15-5 15-10 0-12-7-20-15-20-14 0-25 8-25 20 0 16 11 30 25 30 19 0 35-14 35-30 0-23-16-40-35-40-25 0-45 17-45 40 0 27 20 50 45 50 30 0 55-23 55-50 0-34-25-60-55-60" style="fill:#fff;stroke:red;stroke-width:2"/></svg></i>
语言</a></div><ul class=mobile-submenu-list><li><a href=/><strong></strong></a></li><li><a href=/en/></a></li><li><a href=/fr/></a></li><li><a href=/de/></a></li></ul></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>火山灰</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>首页</a></li><li class=menu-item><a class=menu-item-link href=/post/>时间轴</a></li><li class=menu-item><a class=menu-item-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-item-link href=/categories/>归档</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li><li class=menu-item><a class="menu-item-link menu-parent menu-item-lang" href=#><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M912.569234 73.142857a88.429714 88.429714.0 0188.576 89.161143v296.557714C1001.145234 732.562286 782.301806 950.857143 510.28352 950.857143A489.837714 489.837714.0 0118.288091 458.861714V162.304a90.002286 90.002286.0 0189.161143-89.161143h805.156572zm-402.285714 608a68.388571 68.388571.0 0046.848-18.870857l230.838857-221.696a68.022857 68.022857.0 0021.138286-48.566857 67.547429 67.547429.0 00-114.285714-48.566857l-184.576 177.152-184.576-177.152a67.328 67.328.0 00-46.299429-18.870857A67.547429 67.547429.0 00232.486949 440.576l231.424 221.696c11.995429 11.995429 29.147429 18.870857 46.299428 18.870857z"/></svg></i></a><ul class=submenu><li><a href=/>zh-cn</a></li><li><a href=/en/>en</a></li><li><a href=/fr/>fr</a></li><li><a href=/de/>de</a></li></ul></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>转载 | 自然语言处理入门</h1><div class=post-meta><time datetime=0001-01-01 class=post-time>0001-01-01</time><div class=post-category><a href=/categories/%E7%BC%96%E7%A8%8B%E4%B8%96%E7%95%8C/>编程世界</a></div><span class=more-meta>约 11948 字</span>
<span class=more-meta>预计阅读 24 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#一文本相似度计算>一、文本相似度计算</a><ul><li><a href=#tf-idf模型>TF-IDF模型</a></li><li><a href=#lsi模型>LSI模型</a></li><li><a href=#lda模型>LDA模型</a></li></ul></li><li><a href=#二中文文本处理利器snownlp>二、中文文本处理利器<code>snownlp</code></a></li><li><a href=#三word2vec>三、Word2Vec</a><ul><li><a href=#电商评论数据获取>电商评论数据获取</a></li><li><a href=#中文分词>中文分词</a></li><li><a href=#word2vec测试>Word2Vec测试</a></li></ul></li><li><a href=#四中文分词原理及分词工具介绍>四、中文分词原理及分词工具介绍</a><ul><li><a href=#中文分词原理介绍>中文分词原理介绍</a></li><li><a href=#中文分词工具介绍>中文分词工具介绍</a></li></ul></li><li><a href=#五基于wordart的agm手机评论词频分析>五、基于WordArt的AGM手机评论词频分析</a><ul><li><a href=#获取评论数据>获取评论数据</a></li><li><a href=#用wordart做词频分析>用WordArt做词频分析</a></li></ul></li><li><a href=#六基于lda的文章主题生成>六、基于LDA的文章主题生成</a><ul><li><a href=#lda概述>LDA概述</a></li><li><a href=#基于lda的文章主题生成>基于LDA的文章主题生成</a></li></ul></li><li><a href=#七基于tf-idf的文本自动打标>七、基于TF-IDF的文本自动打标</a><ul><li><a href=#tf-idf简介>TF-IDF简介</a></li><li><a href=#应用案例>应用案例</a></li></ul></li><li><a href=#八textrank>八、TextRank</a></li></ul></nav></div></div><div class=post-content><p>先整理一些资料。</p><h2 id=一文本相似度计算>一、文本相似度计算</h2><p><strong>文本相似度计算</strong>在信息检索、数据挖掘、机器翻译、文档复制检测等领域有着广泛的应用。文本相似度常用的计算方法有<strong>TF-IDF</strong>、<strong>LSI</strong>、<strong>LDA</strong>等。</p><h3 id=tf-idf模型>TF-IDF模型</h3><p><strong>TF-IDF（Term Frequency-Inverse Document Frequency）<strong>是一种统计方法，用以评估某一字词对于一个文件集或一个语料库中的其中一份</strong>文件</strong>的<strong>重要程度</strong>。</p><blockquote><p><strong>字词</strong>的重要性随着它在<strong>文件</strong>中出现的次数成<strong>正比增加</strong>，但同时会随着它在<strong>语料库</strong>中出现的<strong>频率</strong>成<strong>反比下降</strong>。</p></blockquote><p><strong>TF-IDF</strong>加权的各种形式常被<strong>搜寻引擎</strong>应用，作为<strong>文件与用户查询之间相关程</strong>度的度量或评级。</p><p>在一份给定的文件里，<strong>词频 (term frequency, TF)</strong> 指的是<strong>某一个给定的词语在该文件中出现的次数</strong>。这个数字通常会被<strong>归一化</strong>，以防止它偏向长的文件。</p><p><strong>逆向文件频率 (inverse document frequency, IDF)</strong> 是一个<strong>词语普遍重要性的度量</strong>。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。</p><p><strong>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF</strong>。因此，TF-IDF倾向于<strong>过滤掉常见的词语，保留重要的词语</strong>。</p><p><strong>TF-IDF</strong>的主要思想是：<strong>如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。</strong></p><h3 id=lsi模型>LSI模型</h3><p><strong>LSI（Latent Semantic Indexing）<strong>又称为</strong>潜在语义分析(LSA)</strong>，是在信息检索领域提出来的一个概 念。主要用于解决<strong>一词多义</strong>（如**“bank”**一词，可以指银行，也可以指河岸）和**一义多词**（如**“car”**和**“automobile”**具有相同的含义）。依靠余弦相似性的方法并不能很好地解决上述问题，所以提出了**潜在语义索引**的方法，利用**SVD降维**的方法**将词项和文本映射到一个新的空间**。</p><h3 id=lda模型>LDA模型</h3><p><strong>LDA（Latent Dirichlet Allocation）<strong>是一种</strong>文档主题生成模型</strong>，也称为一个<strong>三层贝叶斯概率</strong>模型，包含<strong>词</strong>、<strong>主题</strong>和<strong>文档</strong>三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“<strong>以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语</strong>”这样一个过程得到。<strong>文档到主题服从多项式分布，主题到词服从多项式分布</strong>。</p><p><strong>LDA</strong>是一种非监督机器学习技术，可以用来<strong>识别大规模文档集</strong>（document collection）或<strong>语料库</strong>（corpus）中<strong>潜藏的主题信息</strong>。它采用了词袋（bag of words）的方法，这种方法<strong>将每一篇文档视为一个词频向量</strong>，从而将<strong>文本信息</strong>转化为了易于建模的<strong>数字信息</strong>。但是词袋方法没有考虑词与词之间的顺序，这简化了问题的复杂性，同时也为模型的改进提供了契机。<strong>每一篇文档</strong>代表了<strong>一些主题所构成的一个概率分布</strong>，而<strong>每一个主题</strong>又代表了<strong>很多单词所构成的一个概率分布</strong>。</p><h2 id=二中文文本处理利器snownlp>二、中文文本处理利器<code>snownlp</code></h2><p><strong>SnowNLP</strong>是一个python写的类库，可以方便的处理<strong>中文文本</strong>内容。如<strong>中文分词</strong>、<strong>词性标注</strong>、<strong>情感分析</strong>、<strong>文本分类</strong>、<strong>提取文本关键词</strong>、<strong>文本相似度计算</strong>等。</p><p><code>snownlp</code>示例如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Wed May 31 22:28:23 2017
</span><span class=s2>@author: Administrator
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>from</span> <span class=nn>snownlp</span> <span class=kn>import</span> <span class=n>SnowNLP</span>
<span class=n>s</span> <span class=o>=</span> <span class=n>SnowNLP</span><span class=p>(</span><span class=sa>u</span><span class=s1>&#39;这个东西真心很赞&#39;</span><span class=p>)</span>

<span class=n>s</span><span class=o>.</span><span class=n>words</span>         <span class=c1># [u&#39;这个&#39;, u&#39;东西&#39;, u&#39;真心&#39;, u&#39;很&#39;, u&#39;赞&#39;]</span>
<span class=n>s</span><span class=o>.</span><span class=n>tags</span>          <span class=c1># [(u&#39;这个&#39;, u&#39;r&#39;), (u&#39;东西&#39;, u&#39;n&#39;), (u&#39;真心&#39;, u&#39;d&#39;), (u&#39;很&#39;, u&#39;d&#39;), (u&#39;赞&#39;, u&#39;Vg&#39;)]</span>

<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>sentiments</span><span class=p>)</span>    <span class=c1># 0.9769663402895832 positive的概率</span>
<span class=c1>#汉转拼音</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>pinyin</span><span class=p>)</span>        <span class=c1># [u&#39;zhe&#39;, u&#39;ge&#39;, u&#39;dong&#39;, u&#39;xi&#39;,</span>
                       <span class=c1>#  u&#39;zhen&#39;, u&#39;xin&#39;, u&#39;hen&#39;, u&#39;zan&#39;]</span>
<span class=n>s</span> <span class=o>=</span> <span class=n>SnowNLP</span><span class=p>(</span><span class=sa>u</span><span class=s1>&#39;「繁體字」「繁體中文」的叫法在臺灣亦很常見。&#39;</span><span class=p>)</span>
<span class=c1>#简转繁</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>han</span><span class=p>)</span>    <span class=c1># 输出是：u&#39;「繁体字」「繁体中文」的叫法在台湾亦很常见。&#39;</span>

<span class=n>text</span> <span class=o>=</span> <span class=sa>u</span><span class=s1>&#39;&#39;&#39;
</span><span class=s1>自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。
</span><span class=s1>它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。
</span><span class=s1>自然语言处理是一门融语言学、计算机科学、数学于一体的科学。
</span><span class=s1>因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，
</span><span class=s1>所以它与语言学的研究有着密切的联系，但又有重要的区别。
</span><span class=s1>自然语言处理并不是一般地研究自然语言，
</span><span class=s1>而在于研制能有效地实现自然语言通信的计算机系统，
</span><span class=s1>特别是其中的软件系统。因而它是计算机科学的一部分。
</span><span class=s1>&#39;&#39;&#39;</span>

<span class=n>s</span> <span class=o>=</span> <span class=n>SnowNLP</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
<span class=n>s</span><span class=o>.</span><span class=n>keywords</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>   <span class=c1># [u&#39;语言&#39;, u&#39;自然&#39;, u&#39;计算机&#39;]</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>summary</span><span class=p>(</span><span class=mi>3</span><span class=p>))</span> <span class=c1># [u&#39;因而它是计算机科学的一部分&#39;,</span>
                    <span class=c1>#  u&#39;自然语言处理是一门融语言学、计算机科学、数学于一体的科学&#39;,</span>
                    <span class=c1>#  u&#39;自然语言处理是计算机科学领域与人工智能领域中的一个重要方向&#39;]</span>
<span class=n>s</span><span class=o>.</span><span class=n>sentences</span>

<span class=n>s</span> <span class=o>=</span> <span class=n>SnowNLP</span><span class=p>([[</span><span class=sa>u</span><span class=s1>&#39;这篇&#39;</span><span class=p>,</span> <span class=sa>u</span><span class=s1>&#39;文章&#39;</span><span class=p>],</span>
             <span class=p>[</span><span class=sa>u</span><span class=s1>&#39;那篇&#39;</span><span class=p>,</span> <span class=sa>u</span><span class=s1>&#39;论文&#39;</span><span class=p>],</span>
             <span class=p>[</span><span class=sa>u</span><span class=s1>&#39;这个&#39;</span><span class=p>]])</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>tf</span><span class=p>)</span>   <span class=c1>#词频</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>idf</span><span class=p>)</span>  <span class=c1>#逆向文件频率</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>sim</span><span class=p>([</span><span class=sa>u</span><span class=s1>&#39;文章&#39;</span><span class=p>]))</span>  <span class=c1># [0.3756070762985226, 0, 0]</span>
</code></pre></td></tr></table></div></div><p>运行结果如下图所示：</p><p><img src=./images/20170531223614941.gif alt></p><h2 id=三word2vec>三、Word2Vec</h2><p><strong>Word2Vec</strong>是2013年Google开源的一款用于<strong>词向量计算</strong>的工具，由于其可以在百万数量级的词典和上亿的数据集上进行高效地训练，且该工具得到的词向量，可以很好地<strong>度量词与词之间的相似性</strong>，在学术界和工业界都得到了广泛的应用。</p><p>word2vec采用的是<strong>n元语法模型</strong>(n-gram model)，即假设一个词只与周围n个词有关，而与文本中的其他词无关。其训练词向量有两种方式：<strong>CBOW</strong>和<strong>Skip-gram</strong>。
（1）CBOW（Continuous Bag of words,连续词袋模型）：用其上下文词，来预测当前词生成的概率。
（2）Skip-Gram：用当前词去预测上下文词的生成概率。</p><p>本文就以Python中的<strong>gensim</strong>为例，介绍下Word2Vec的特性。主要可以分为<strong>电商评论数据获取</strong>、<strong>中文分词</strong>、<strong>Word2Vec测试</strong>三部分。</p><h3 id=电商评论数据获取>电商评论数据获取</h3><p>本文的测试数据集来自于华为荣耀天猫旗舰店荣耀V10手机的评论数据（天猫页面链接：<a href="https://detail.tmall.com/item.htm?spm=a1z10.1-b-s.w13636028-15291748785.6.70ea7f34skZgjc&id=562003579553&sku_properties=10004:653780895;5919063:6536025">https://detail.tmall.com/item.htm?spm=a1z10.1-b-s.w13636028-15291748785.6.70ea7f34skZgjc&id=562003579553&sku_properties=10004:653780895;5919063:6536025</a>），共计3000条。</p><p>获取天猫评论数据的方法，在链接<a href=http://blog.csdn.net/flysky1991/article/details/74586286>http://blog.csdn.net/flysky1991/article/details/74586286</a>
中有详细说明，就不再多说了。实现代码如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Thu Feb  1 18:10:52 2018
</span><span class=s2>
</span><span class=s2>@author: zch
</span><span class=s2>&#34;&#34;&#34;</span>


<span class=kn>import</span> <span class=nn>requests</span>
<span class=kn>import</span> <span class=nn>json</span>
<span class=kn>import</span> <span class=nn>time</span>
<span class=kn>import</span> <span class=nn>random</span>
<span class=kn>import</span> <span class=nn>pymysql.cursors</span>

<span class=s1>&#39;&#39;&#39;
</span><span class=s1>荣耀V10天猫原始链接：https://detail.tmall.com/item.htm?spm=a1z10.1-b-s.w13636028-15291748785.6.70ea7f34skZgjc&amp;id=562003579553&amp;sku_properties=10004:653780895;5919063:6536025
</span><span class=s1>&#39;&#39;&#39;</span>


<span class=k>def</span> <span class=nf>crawlProductComment</span><span class=p>(</span><span class=n>url</span><span class=p>,</span><span class=n>page</span><span class=p>):</span>

    <span class=c1>#商品评论的JSON数据</span>
    <span class=c1>#url = &#39;https://rate.tmall.com/list_detail_rate.htm?itemId=562003579553&amp;spuId=101717810&amp;spuId=101717810&amp;sellerId=1114511827&amp;order=3&amp;currentPage=1&amp;append=⊙&amp;content=1&#39;</span>
    <span class=n>req</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span>
    <span class=n>jsondata</span> <span class=o>=</span> <span class=n>req</span><span class=o>.</span><span class=n>text</span><span class=p>[</span><span class=mi>15</span><span class=p>:]</span>
    <span class=n>data</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>jsondata</span><span class=p>)</span>

    <span class=c1>#输出页面信息</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;正在获取第{}页的评论数据！&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;paginator&#39;</span><span class=p>][</span><span class=s1>&#39;page&#39;</span><span class=p>]))</span>
    <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=c1>#遍历评论信息列表</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>data</span><span class=p>[</span><span class=s2>&#34;rateList&#34;</span><span class=p>]:</span>
        <span class=n>j</span> <span class=o>=</span> <span class=n>j</span> <span class=o>+</span> <span class=mi>1</span>
        <span class=k>if</span> <span class=n>page</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>:</span>
                <span class=n>k</span> <span class=o>=</span> <span class=s1>&#39;00&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39;0&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>j</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>k</span> <span class=o>=</span> <span class=s1>&#39;00&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>j</span><span class=p>)</span>
        <span class=k>elif</span> <span class=n>page</span> <span class=o>&lt;</span> <span class=mi>100</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>:</span>
                <span class=n>k</span> <span class=o>=</span> <span class=s1>&#39;0&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39;0&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>j</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>k</span> <span class=o>=</span> <span class=s1>&#39;0&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>j</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>:</span>
                <span class=n>k</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39;0&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>j</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>k</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>j</span><span class=p>)</span>
        <span class=c1>#输出商品sku信息</span>
        <span class=n>auctionSku</span> <span class=o>=</span> <span class=n>i</span><span class=p>[</span><span class=s1>&#39;auctionSku&#39;</span><span class=p>]</span>
        <span class=n>rateDate</span> <span class=o>=</span> <span class=n>i</span><span class=p>[</span><span class=s1>&#39;rateDate&#39;</span><span class=p>]</span>
        <span class=n>rateContent</span> <span class=o>=</span> <span class=n>i</span><span class=p>[</span><span class=s1>&#39;rateContent&#39;</span><span class=p>]</span>

        <span class=n>info</span> <span class=o>=</span> <span class=n>i</span><span class=p>[</span><span class=s1>&#39;appendComment&#39;</span><span class=p>]</span>
        <span class=k>if</span> <span class=n>info</span><span class=p>:</span>
            <span class=n>appendCommentTime</span> <span class=o>=</span> <span class=n>info</span><span class=p>[</span><span class=s1>&#39;commentTime&#39;</span><span class=p>]</span>
            <span class=n>appendCommentContent</span> <span class=o>=</span> <span class=n>info</span><span class=p>[</span><span class=s1>&#39;content&#39;</span><span class=p>]</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>appendCommentTime</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
            <span class=n>appendCommentContent</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>


        <span class=k>print</span><span class=p>(</span><span class=s2>&#34;第{}个商品的sku:{}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>k</span><span class=p>,</span><span class=n>auctionSku</span><span class=p>))</span>
        <span class=c1>#输出评论时间和评论内容</span>
        <span class=k>print</span><span class=p>(</span><span class=s2>&#34;评论时间：{}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>rateDate</span><span class=p>))</span>
        <span class=k>print</span><span class=p>(</span><span class=s2>&#34;评论内容：{}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>rateContent</span><span class=p>))</span>
        <span class=n>info</span> <span class=o>=</span> <span class=n>i</span><span class=p>[</span><span class=s1>&#39;appendComment&#39;</span><span class=p>]</span>
        <span class=c1>#判断是否有追加评论</span>
        <span class=k>if</span> <span class=n>info</span><span class=p>:</span>
            <span class=k>print</span><span class=p>(</span><span class=s2>&#34;追评时间:{}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>appendCommentTime</span><span class=p>))</span>
            <span class=k>print</span><span class=p>(</span><span class=s2>&#34;追评内容:{}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>appendCommentContent</span><span class=p>))</span>
        <span class=k>print</span><span class=p>(</span><span class=s2>&#34;-------------------------------------------------&#34;</span><span class=p>)</span>

        <span class=s1>&#39;&#39;&#39;
</span><span class=s1>        数据库操作
</span><span class=s1>        &#39;&#39;&#39;</span>

        <span class=c1>#获取数据库链接</span>
        <span class=n>connection</span>  <span class=o>=</span> <span class=n>pymysql</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=n>host</span> <span class=o>=</span> <span class=s1>&#39;localhost&#39;</span><span class=p>,</span>
                                  <span class=n>user</span> <span class=o>=</span> <span class=s1>&#39;root&#39;</span><span class=p>,</span>
                                  <span class=n>password</span> <span class=o>=</span> <span class=s1>&#39;123456&#39;</span><span class=p>,</span>
                                  <span class=n>db</span> <span class=o>=</span> <span class=s1>&#39;tmall&#39;</span><span class=p>,</span>
                                  <span class=n>charset</span> <span class=o>=</span> <span class=s1>&#39;utf8mb4&#39;</span><span class=p>)</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=c1>#获取会话指针</span>
            <span class=k>with</span> <span class=n>connection</span><span class=o>.</span><span class=n>cursor</span><span class=p>()</span> <span class=k>as</span> <span class=n>cursor</span><span class=p>:</span>
                <span class=c1>#创建sql语句</span>
                <span class=n>sql</span> <span class=o>=</span> <span class=s2>&#34;insert into `HonorV10_Comment` (`id`,`auctionSku`,`rateDate`,`rateContent`,`appendCommentTime`,`appendCommentContent`) values (</span><span class=si>%s</span><span class=s2>,</span><span class=si>%s</span><span class=s2>,</span><span class=si>%s</span><span class=s2>,</span><span class=si>%s</span><span class=s2>,</span><span class=si>%s</span><span class=s2>,</span><span class=si>%s</span><span class=s2>)&#34;</span>

                <span class=c1>#执行sql语句</span>
                <span class=n>cursor</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>sql</span><span class=p>,(</span><span class=n>k</span><span class=p>,</span><span class=n>auctionSku</span><span class=p>,</span><span class=n>rateDate</span><span class=p>,</span><span class=n>rateContent</span><span class=p>,</span><span class=n>appendCommentTime</span><span class=p>,</span><span class=n>appendCommentContent</span><span class=p>))</span>

                <span class=c1>#提交数据库</span>
                <span class=n>connection</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
        <span class=k>finally</span><span class=p>:</span>
            <span class=n>connection</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>


<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>l</span><span class=p>,</span><span class=mi>151</span><span class=p>):</span>
    <span class=c1>#print(&#34;正在获取第{}页评论数据!&#34;.format(i+1))</span>
    <span class=c1>#获取荣耀V10评论JSON链接,通过更改page参数的值来循环读取多页评论信息</span>
    <span class=c1>#itemId:&#34;562003579553&#34;,sellerId:&#34;1114511827&#34;,shopId:&#34;101717810&#34;</span>
    <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://rate.tmall.com/list_detail_rate.htm?itemId=562003579553&amp;spuId=101717810&amp;spuId=101717810&amp;sellerId=1114511827&amp;order=3&amp;currentPage=&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>i</span><span class=p>)</span> <span class=o>+</span><span class=s1>&#39;&amp;append=⊙&amp;content=1&#39;</span>
    <span class=n>crawlProductComment</span><span class=p>(</span><span class=n>url</span><span class=p>,</span><span class=n>i</span><span class=p>)</span>
    <span class=c1>#设置休眠时间</span>
    <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span><span class=mi>66</span><span class=p>))</span>

</code></pre></td></tr></table></div></div><h3 id=中文分词>中文分词</h3><p>本文采用的是jieba来对评论数据进行分词操作。实现代码如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Wed Feb  7 11:23:27 2018
</span><span class=s2>
</span><span class=s2>@author: zch
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>pandas</span> <span class=kn>as</span> <span class=nn>pd</span>
<span class=kn>import</span> <span class=nn>pymysql.cursors</span>
<span class=kn>import</span> <span class=nn>re</span>
<span class=kn>import</span> <span class=nn>jieba</span>

<span class=s1>&#39;&#39;&#39;
</span><span class=s1>数据库操作
</span><span class=s1>&#39;&#39;&#39;</span>

<span class=c1>#获取数据库链接</span>
<span class=n>connection</span>  <span class=o>=</span> <span class=n>pymysql</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=n>host</span> <span class=o>=</span> <span class=s1>&#39;localhost&#39;</span><span class=p>,</span>
                          <span class=n>user</span> <span class=o>=</span> <span class=s1>&#39;root&#39;</span><span class=p>,</span>
                          <span class=n>password</span> <span class=o>=</span> <span class=s1>&#39;123456&#39;</span><span class=p>,</span>
                          <span class=n>db</span> <span class=o>=</span> <span class=s1>&#39;tmall&#39;</span><span class=p>,</span>
                          <span class=n>charset</span> <span class=o>=</span> <span class=s1>&#39;utf8mb4&#39;</span><span class=p>)</span>
<span class=k>try</span><span class=p>:</span>
    <span class=c1>#获取会话指针</span>
    <span class=k>with</span> <span class=n>connection</span><span class=o>.</span><span class=n>cursor</span><span class=p>()</span> <span class=k>as</span> <span class=n>cursor</span><span class=p>:</span>
        <span class=c1>#创建sql语句</span>
        <span class=n>sql</span> <span class=o>=</span> <span class=s2>&#34;select * from `HonorV10_Comment` limit 3000&#34;</span>

        <span class=c1>#执行sql语句</span>
        <span class=n>cursor</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>sql</span><span class=p>)</span>
        <span class=n>data</span> <span class=o>=</span> <span class=n>cursor</span><span class=o>.</span><span class=n>fetchall</span><span class=p>()</span>
        <span class=c1>#print(data[1000])</span>
        <span class=c1>#print(data[1][1])</span>
        <span class=c1>#提交数据库</span>
        <span class=n>connection</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
<span class=k>finally</span><span class=p>:</span>
    <span class=n>connection</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>

<span class=n>f1</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;tmall_review.txt&#34;</span><span class=p>,</span><span class=s1>&#39;a&#39;</span><span class=p>)</span> 
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>3000</span><span class=p>):</span>
    <span class=n>line</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>3</span><span class=p>]</span>
    <span class=k>print</span><span class=p>(</span><span class=n>line</span><span class=p>)</span>
    <span class=c1># 中文的编码范围是：\u4e00到\u9fa5 </span>
    <span class=n>p2</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;[^\u4e00-\u9fa5]&#39;</span><span class=p>)</span>  
    <span class=n>result</span> <span class=o>=</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>p2</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>line</span><span class=p>))</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> 
    <span class=c1>#line.replace(&#39;\t&#39;,&#39;&#39;).replace(&#39;\n&#39;,&#39;&#39;).replace(&#39; &#39;,&#39;&#39;)</span>
    <span class=n>cutline</span> <span class=o>=</span> <span class=n>jieba</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=n>result</span><span class=p>,</span><span class=n>cut_all</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
    <span class=n>f1</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cutline</span><span class=p>))</span>

<span class=n>f1</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>

</code></pre></td></tr></table></div></div><h3 id=word2vec测试>Word2Vec测试</h3><p>首先，读取经过jieba分词的评论数据，然后分别测试词语之间的相似度、某个词的相关词表和词语间的对应关系。实现代码如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Wed Feb  7 11:21:39 2018
</span><span class=s2>
</span><span class=s2>@author: zch
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>from</span> <span class=nn>gensim.models</span> <span class=kn>import</span> <span class=n>word2vec</span>
<span class=kn>import</span> <span class=nn>logging</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=kn>as</span> <span class=nn>pd</span>

<span class=c1># 主程序  </span>
<span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>format</span><span class=o>=</span><span class=s1>&#39;</span><span class=si>%(asctime)s</span><span class=s1>:</span><span class=si>%(levelname)s</span><span class=s1>: </span><span class=si>%(message)s</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>)</span>  


<span class=c1># 加载语料,默认为utf-8编码</span>
<span class=n>sentences</span> <span class=o>=</span><span class=n>word2vec</span><span class=o>.</span><span class=n>Text8Corpus</span><span class=p>(</span><span class=sa>u</span><span class=s2>&#34;D:</span><span class=se>\\</span><span class=s2>data/tmall/tmall_review.txt&#34;</span><span class=p>)</span>


<span class=c1>#训练skip-gram模型，默认window=5</span>
<span class=n>model</span> <span class=o>=</span><span class=n>word2vec</span><span class=o>.</span><span class=n>Word2Vec</span><span class=p>(</span><span class=n>sentences</span><span class=p>,</span><span class=n>size</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>    

<span class=k>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>

<span class=c1># 计算两个词的相似度/相关程度  </span>
<span class=k>try</span><span class=p>:</span>  
    <span class=c1>#最新版本的用法，老版本用法为y1 = model.similarity(u&#34;苹果&#34;, u&#34;华为&#34;)，下同。  </span>
    <span class=n>y1</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>wv</span><span class=o>.</span><span class=n>similarity</span><span class=p>(</span><span class=sa>u</span><span class=s2>&#34;华为&#34;</span><span class=p>,</span> <span class=sa>u</span><span class=s2>&#34;手机&#34;</span><span class=p>)</span>  
<span class=k>except</span> <span class=ne>KeyError</span><span class=p>:</span>  
    <span class=n>y1</span> <span class=o>=</span> <span class=mi>0</span>  
<span class=k>print</span> <span class=p>(</span><span class=sa>u</span><span class=s2>&#34;【华为】和【手机】的相似度为：&#34;</span><span class=p>,</span> <span class=n>y1</span><span class=p>)</span>  
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;------------------------</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>

<span class=c1>#计算某个词的相关词列表(topn=10)</span>
<span class=n>y2</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>wv</span><span class=o>.</span><span class=n>most_similar</span><span class=p>(</span><span class=sa>u</span><span class=s2>&#34;物流&#34;</span><span class=p>,</span><span class=n>topn</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=sa>u</span><span class=s2>&#34;和【物流】最相关的词有：</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>y2</span><span class=p>:</span>
    <span class=k>print</span><span class=p>(</span><span class=n>item</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>item</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;------------------------</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>

<span class=c1># 寻找对应关系  </span>
<span class=k>print</span> <span class=p>(</span><span class=sa>u</span><span class=s2>&#34;上网-流畅，拍照-&#34;</span><span class=p>)</span>  
<span class=n>y3</span> <span class=o>=</span><span class=n>model</span><span class=o>.</span><span class=n>wv</span><span class=o>.</span><span class=n>most_similar</span><span class=p>([</span><span class=sa>u</span><span class=s1>&#39;上网&#39;</span><span class=p>,</span> <span class=sa>u</span><span class=s1>&#39;流畅&#39;</span><span class=p>],</span> <span class=p>[</span><span class=sa>u</span><span class=s1>&#39;拍照&#39;</span><span class=p>],</span><span class=n>topn</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>  
<span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>y3</span><span class=p>:</span>  
    <span class=k>print</span><span class=p>(</span><span class=n>item</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>item</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>  
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;------------------------</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>

</code></pre></td></tr></table></div></div><p><img src=./images/20180226105400187.gif alt=img></p><h2 id=四中文分词原理及分词工具介绍>四、中文分词原理及分词工具介绍</h2><p>本文首先介绍下<strong>中文分词</strong>的<strong>基本原理</strong>，然后介绍下国内比较流行的<strong>中文分词工具</strong>，如<strong>jieba</strong>、<strong>SnowNLP</strong>、<strong>THULAC</strong>、<strong>NLPIR</strong>，上述分词工具都已经在<strong>github</strong>上开源，后续也会附上github链接，以供参考。</p><h3 id=中文分词原理介绍>中文分词原理介绍</h3><h4 id=中文分词概述>中文分词概述</h4><p><strong>中文分词(Chinese Word Segmentation)</strong> 指的是<strong>将一个汉字序列切分成一个一个单独的词</strong>。<strong>分词</strong>就是<strong>将连续的字序列按照一定的规范重新组合成词序列的过程</strong>。</p><h4 id=中文分词方法介绍>中文分词方法介绍</h4><p>现有的<strong>分词方法</strong>可分为三大类：<strong>基于字符串匹配的分词方法</strong>、<strong>基于理解的分词方法</strong>和<strong>基于统计的分词方法</strong>。</p><h5 id=基于字符串匹配的分词方法>基于字符串匹配的分词方法</h5><p><strong>基于字符串匹配的分词方法</strong>又称<strong>机械分词方法</strong>，它是按照<strong>一定的策略</strong>将<strong>待分析的汉字串</strong>与一个“<strong>充分大的”机器词典</strong>中的词条进行配，<strong>若在词典中找到某个字符串</strong>，则<strong>匹配成功</strong>（识别出一个词）。</p><p>按照<strong>扫描方向</strong>的不同，字符串匹配分词方法可以分为<strong>正向匹配</strong>和<strong>逆向匹配</strong>；按照<strong>不同长度优先匹配</strong>的情况，可以分为<strong>最大（最长）匹配</strong>和<strong>最小（最短）匹配</strong>；按照<strong>是否与词性标注过程相结合</strong>，可以分为<strong>单纯分词方法</strong>和<strong>分词与词性标注相结合的一体化方法</strong>。常用的<strong>字符串匹配方法</strong>有如下几种：</p><p>（1）<strong>正向最大匹配法</strong>（从左到右的方向）；</p><p>（2）<strong>逆向最大匹配法</strong>（从右到左的方向）；</p><p>（3）<strong>最小切分</strong>（每一句中切出的词数最小）；</p><p>（4）<strong>双向最大匹配</strong>（进行从左到右、从右到左两次扫描）</p><p>这类算法的<strong>优点是速度快</strong>，时间复杂度可以保持在O（n）,实现简单，效果尚可；但对<strong>歧义</strong>和<strong>未登录词</strong>处理效果不佳。</p><h5 id=基于理解的分词方法>基于理解的分词方法</h5><p><strong>基于理解的分词方法</strong>是<strong>通过让计算机模拟人对句子的理解</strong>，达到识别词的效果。其<strong>基本思想</strong>就是<strong>在分词的同时进行句法、语义分析</strong>，利用<strong>句法信息</strong>和<strong>语义信息</strong>来<strong>处理歧义</strong>现象。它通常包括三个部分：<strong>分词子系统</strong>、<strong>句法语义子系统</strong>、<strong>总控部分</strong>。在<strong>总控部分</strong>的协调下，<strong>分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断</strong>，即它模拟了人对句子的理解过程。这种分词方法<strong>需要使用大量的语言知识和信息</strong>。由于汉语语言知识的笼统、复杂性，难以将各种语言信息组织成机器可直接读取的形式，因此目前基于理解的分词系统还处在<strong>试验阶段</strong>。</p><h5 id=基于统计的分词方法>基于统计的分词方法</h5><p><strong>基于统计的分词方法</strong>是在<strong>给定大量已经分词的文本</strong>的前提下，<strong>利用统计机器学习模型学习词语切分的规律</strong>（称为<strong>训练</strong>），从而实现<strong>对未知文本的切分</strong>。例如<strong>最大概率分词方法</strong>和<strong>最大熵分词方法</strong>等。随着大规模语料库的建立，统计机器学习方法的研究和发展，<strong>基于统计的中文分词方法渐渐成为了主流方法</strong></p><p>主要的<strong>统计模型</strong>有：<strong>N元文法模型</strong>（N-gram），<strong>隐马尔可夫模型</strong>（Hidden Markov Model ，HMM），<strong>最大熵模型</strong>（ME），<strong>条件随机场模型</strong>（Conditional Random Fields，CRF）等。</p><p>在实际的应用中，<strong>基于统计的分词系统</strong>都需要使用<strong>分词词典</strong>来<strong>进行字符串匹配分词</strong>，同时<strong>使用统计方法识别一些新词</strong>，即将<strong>字符串频率统计</strong>和<strong>字符串匹配</strong>结合起来，既发挥<strong>匹配分词切分速度快、效率高的特点</strong>，又利用了<strong>无词典分词结合上下文识别生词、自动消除歧义的优点</strong>。</p><h3 id=中文分词工具介绍>中文分词工具介绍</h3><h4 id=jieba-github-star数-9003>jieba (github star数 9003)</h4><p><strong>jieba分词</strong>是国内使用人数最多的<strong>中文分词工具</strong>（github链接：<a href=https://github.com/fxsjy/jieba>https://github.com/fxsjy/jieba</a>）。<strong>jieba分词</strong>支持<strong>三种模式</strong>：</p><p>（1）<strong>精确模式</strong>：试图将句子最精确地切开，<strong>适合文本分析</strong>；</p><p>（2）<strong>全模式</strong>：把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是<strong>不能解决歧义</strong>；</p><p>（3）<strong>搜索引擎模式</strong>：在精确模式的基础上，<strong>对长词再次切分，提高召回率</strong>，<strong>适合用于搜索引擎分词</strong>。</p><p><strong>jieba分词</strong>过程中主要涉及如下几种算法：</p><p>（1）基于<strong>前缀词典</strong>实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)；</p><p>（2）采用了<strong>动态规划</strong>查找最大概率路径, 找出<strong>基于词频的最大切分组合</strong>；</p><p>（3）对于<strong>未登录词</strong>，采用了基于汉字成词能力的 <strong>HMM 模型</strong>，采用<strong>Viterbi 算法</strong>进行计算；</p><p>（4）基于<strong>Viterbi</strong>算法做<strong>词性标注</strong>；</p><p>（5）基于<strong>tf-idf</strong>和<strong>textrank</strong>模型<strong>抽取关键词</strong>；</p><p><strong>测试代码</strong>如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>jieba分词测试
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>jieba</span>


<span class=c1>#全模式</span>
<span class=n>test1</span> <span class=o>=</span> <span class=n>jieba</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=s2>&#34;杭州西湖风景很好，是旅游胜地！&#34;</span><span class=p>,</span> <span class=n>cut_all</span><span class=o>=</span><span class=bp>True</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;全模式: &#34;</span> <span class=o>+</span> <span class=s2>&#34;| &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>test1</span><span class=p>))</span>

<span class=c1>#精确模式</span>
<span class=n>test2</span> <span class=o>=</span> <span class=n>jieba</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=s2>&#34;杭州西湖风景很好，是旅游胜地！&#34;</span><span class=p>,</span> <span class=n>cut_all</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;精确模式: &#34;</span> <span class=o>+</span> <span class=s2>&#34;| &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>test2</span><span class=p>))</span>

<span class=c1>#搜索引擎模式</span>
<span class=n>test3</span><span class=o>=</span> <span class=n>jieba</span><span class=o>.</span><span class=n>cut_for_search</span><span class=p>(</span><span class=s2>&#34;杭州西湖风景很好，是旅游胜地,每年吸引大量前来游玩的游客！&#34;</span><span class=p>)</span>  
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;搜索引擎模式:&#34;</span> <span class=o>+</span> <span class=s2>&#34;| &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>test3</span><span class=p>))</span>
<span class=mi>1234567891011121314151617181920</span>
</code></pre></td></tr></table></div></div><p><strong>测试结果</strong>如下图所示：</p><p><img src=./images/20170630152809644.gif alt=image></p><h4 id=snownlpgithub-star数-2043>SnowNLP(github star数 2043)</h4><p><strong>SnowNLP</strong>是一个python写的类库(<a href=https://github.com/isnowfy/snownlp>https://github.com/isnowfy/snownlp</a>)，可以方便的<strong>处理中文文本内容</strong>，是受到了<strong>TextBlob</strong>的启发而写的。SnowNLP主要包括如下几个功能：</p><p>（1）<strong>中文分词</strong>（Character-Based Generative Model）；</p><p>（2）<strong>词性标注</strong>（3-gram HMM）；</p><p>（3）<strong>情感分析</strong>（简单分析，如评价信息）；</p><p>（4）<strong>文本分类</strong>（Naive Bayes）</p><p>（5）<strong>转换成拼音</strong>（Trie树实现的最大匹配）</p><p>（6）<strong>繁简转换</strong>（Trie树实现的最大匹配）</p><p>（7）<strong>文本关键词</strong>和<strong>文本摘要</strong>提取（TextRank算法）</p><p>（8）<strong>计算文档词频</strong>（<strong>TF</strong>，Term Frequency）和<strong>逆向文档频率</strong>（<strong>IDF</strong>，Inverse Document Frequency）</p><p>（9）<strong>Tokenization</strong>（分割成句子）</p><p>（10）<strong>文本相似度计算</strong>（BM25）</p><p><strong>SnowNLP</strong>的最大特点是特别容易上手，用其处理中文文本时能够得到不少有意思的结果，但不少功能比较简单，还有待进一步完善。</p><p><strong>测试代码</strong>如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>SnowNLP测试
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>from</span> <span class=nn>snownlp</span> <span class=kn>import</span> <span class=n>SnowNLP</span>

<span class=n>s</span> <span class=o>=</span> <span class=n>SnowNLP</span><span class=p>(</span><span class=sa>u</span><span class=s1>&#39;杭州西湖风景很好，是旅游胜地,每年吸引大量前来游玩的游客！&#39;</span><span class=p>)</span>

<span class=c1>#分词</span>
<span class=k>print</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>words</span><span class=p>)</span>


<span class=c1>#情感词性计算</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;该文本的情感词性为正的概率:&#34;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>sentiments</span><span class=p>))</span>

<span class=n>text</span> <span class=o>=</span> <span class=sa>u</span><span class=s1>&#39;&#39;&#39;
</span><span class=s1>西湖，位于浙江省杭州市西面，是中国大陆首批国家重点风景名胜区和中国十大风景名胜之一。
</span><span class=s1>它是中国大陆主要的观赏性淡水湖泊之一，也是现今《世界遗产名录》中少数几个和中国唯一一个湖泊类文化遗产。
</span><span class=s1>西湖三面环山，面积约6.39平方千米，东西宽约2.8千米，南北长约3.2千米，绕湖一周近15千米。
</span><span class=s1>湖中被孤山、白堤、苏堤、杨公堤分隔，按面积大小分别为外西湖、西里湖、北里湖、小南湖及岳湖等五片水面，
</span><span class=s1>苏堤、白堤越过湖面，小瀛洲、湖心亭、阮公墩三个小岛鼎立于外西湖湖心，夕照山的雷峰塔与宝石山的保俶塔隔湖相映，
</span><span class=s1>由此形成了“一山、二塔、三岛、三堤、五湖”的基本格局。
</span><span class=s1>&#39;&#39;&#39;</span>

<span class=n>s2</span> <span class=o>=</span> <span class=n>SnowNLP</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>

<span class=c1>#文本关键词提取</span>
<span class=k>print</span><span class=p>(</span><span class=n>s2</span><span class=o>.</span><span class=n>keywords</span><span class=p>(</span><span class=mi>10</span><span class=p>))</span>

</code></pre></td></tr></table></div></div><p><strong>测试结果</strong>如下图所示：</p><p><img src=./images/20170630175309770.gif alt=image></p><h4 id=thulac-github-star数-311>THULAC (github star数 311)</h4><p><strong>THULAC</strong>（THU Lexical Analyzer for Chinese）由<strong>清华大学自然语言处理与社会人文计算实验室</strong>研制推出的一套<strong>中文词法分析工具包</strong>（github链接：<a href=https://github.com/thunlp/THULAC-Python>https://github.com/thunlp/THULAC-Python</a>），具有<strong>中文分词</strong>和<strong>词性标注</strong>功能。<strong>THULAC</strong>具有如下几个特点：</p><p>（1）<strong>能力强</strong>。利用我们集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，<strong>模型标注能力强大</strong>。</p><p>（2）<strong>准确率高</strong>。该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。</p><p>（3）<strong>速度较快</strong>。同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。</p><p><strong>THU词性标记集</strong>（通用版）如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>n/名词 np/人名 ns/地名 ni/机构名 nz/其它专名
m/数词 q/量词 mq/数量词 t/时间词 f/方位词 s/处所词
v/动词 a/形容词 d/副词 h/前接成分 k/后接成分 i/习语 
j/简称 r/代词 c/连词 p/介词 u/助词 y/语气助词
e/叹词 o/拟声词 g/语素 w/标点 x/其它12345
</code></pre></td></tr></table></div></div><p>**测试代码（python版）**如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>THULAC 分词测试
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>thulac</span>   

<span class=c1>#默认模式，分词的同时进行词性标注</span>
<span class=n>test1</span> <span class=o>=</span> <span class=n>thulac</span><span class=o>.</span><span class=n>thulac</span><span class=p>()</span>
<span class=n>text1</span> <span class=o>=</span> <span class=n>test1</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=s2>&#34;杭州西湖风景很好，是旅游胜地！&#34;</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=n>text1</span><span class=p>)</span>


<span class=c1>#只进行分词</span>
<span class=n>test2</span> <span class=o>=</span> <span class=n>thulac</span><span class=o>.</span><span class=n>thulac</span><span class=p>(</span><span class=n>seg_only</span><span class=o>=</span><span class=bp>True</span><span class=p>)</span>
<span class=n>text2</span> <span class=o>=</span> <span class=n>test2</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=s2>&#34;杭州西湖风景很好，是旅游胜地！&#34;</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=n>text2</span><span class=p>)</span><span class=mi>1234567891011121314151617</span>
</code></pre></td></tr></table></div></div><p><strong>测试结果</strong>如下图所示：</p><p><img src=./images/20170630133016929.gif alt=image></p><h4 id=nlpir-github-star数-811>NLPIR (github star数 811)</h4><p><strong>NLPIR分词系统</strong>（前身为2000年发布的<strong>ICTCLAS词法分析系统</strong>，gtihub链接：<a href=https://github.com/NLPIR-team/NLPIR>https://github.com/NLPIR-team/NLPIR</a>），是由<strong>北京理工大学张华平博士</strong>研发的<strong>中文分词系统</strong>，经过十余年的不断完善，拥有丰富的功能和强大的性能。NLPIR是一整套对<strong>原始文本集</strong>进行处理和加工的软件，提供了<strong>中间件处理效果的可视化展示</strong>，也可以作为<strong>小规模数据</strong>的处理加工工具。主要功能包括：<strong>中文分词</strong>，<strong>词性标注</strong>，<strong>命名实体识别</strong>，<strong>用户词典</strong>、<strong>新词发现</strong>与<strong>关键词提取</strong>等功能。本文测试所采用的是<strong>PyNLPIR</strong>（<strong>NLPIR</strong>的<strong>Python版本</strong>，github链接：<a href=https://github.com/tsroten/pynlpir>https://github.com/tsroten/pynlpir</a>）</p><p><strong>测试代码</strong>如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>PYNLPIR 分词测试
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>pynlpir</span>


<span class=c1>#打开分词器</span>
<span class=n>pynlpir</span><span class=o>.</span><span class=n>open</span><span class=p>()</span>

<span class=n>text1</span> <span class=o>=</span> <span class=s2>&#34;杭州西湖风景很好，是旅游胜地,每年吸引大量前来游玩的游客！&#34;</span> 

<span class=c1>#分词，默认打开分词和词性标注功能</span>
<span class=n>test1</span> <span class=o>=</span> <span class=n>pynlpir</span><span class=o>.</span><span class=n>segment</span><span class=p>(</span><span class=n>text1</span><span class=p>)</span>
<span class=c1>#print(test1)</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;1.默认分词模式:</span><span class=se>\n</span><span class=s1>&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>test1</span><span class=p>))</span>

<span class=c1>#将词性标注语言变更为汉语</span>
<span class=n>test2</span> <span class=o>=</span> <span class=n>pynlpir</span><span class=o>.</span><span class=n>segment</span><span class=p>(</span><span class=n>text1</span><span class=p>,</span><span class=n>pos_english</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;2.汉语标注模式:</span><span class=se>\n</span><span class=s1>&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>test2</span><span class=p>))</span>


<span class=c1>#关闭词性标注</span>
<span class=n>test3</span> <span class=o>=</span> <span class=n>pynlpir</span><span class=o>.</span><span class=n>segment</span><span class=p>(</span><span class=n>text1</span><span class=p>,</span><span class=n>pos_tagging</span><span class=o>=</span><span class=bp>False</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;3.无词性标注模式:</span><span class=se>\n</span><span class=s1>&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>test3</span><span class=p>))</span><span class=mi>1234567891011121314151617181920212223242526</span>
</code></pre></td></tr></table></div></div><p><strong>测试结果</strong>如下图所示：</p><p><img src=./images/20170630162020818.gif alt=image></p><h2 id=五基于wordart的agm手机评论词频分析>五、基于WordArt的AGM手机评论词频分析</h2><p>本文首先从<strong>速卖通</strong>（Aliexpress）获取到<strong>AGM X1手机</strong>（战狼2中吴京用的手机）的评论数据，然后利用一个很好的<strong>公开词频分析工具WordArt</strong>(<a href=https://wordart.com/create>https://wordart.com/create</a>)来<strong>对评论数据进行分析</strong>。</p><h3 id=获取评论数据>获取评论数据</h3><p><strong>(1) 评论数据获取python代码如下所示：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Tue Aug 15 16:44:15 2017
</span><span class=s2>
</span><span class=s2>@author: Administrator
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>urllib.request</span>
<span class=kn>from</span> <span class=nn>bs4</span> <span class=kn>import</span> <span class=n>BeautifulSoup</span>
<span class=kn>import</span> <span class=nn>time</span>
<span class=kn>import</span> <span class=nn>random</span>
<span class=kn>import</span> <span class=nn>pymysql.cursors</span>


<span class=k>def</span> <span class=nf>crawl</span><span class=p>(</span><span class=n>url</span><span class=p>,</span><span class=n>i</span><span class=p>):</span>

    <span class=n>html1</span> <span class=o>=</span> <span class=n>urllib</span><span class=o>.</span><span class=n>request</span><span class=o>.</span><span class=n>urlopen</span><span class=p>(</span><span class=n>url</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
    <span class=n>html1</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>html1</span><span class=p>)</span>

    <span class=n>soup1</span> <span class=o>=</span> <span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>html1</span><span class=p>,</span><span class=s1>&#39;lxml&#39;</span><span class=p>)</span>
    <span class=n>result1</span> <span class=o>=</span> <span class=n>soup1</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=n>attrs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;class&#34;</span><span class=p>:</span><span class=s2>&#34;r-time&#34;</span><span class=p>})</span>
    <span class=c1>#print(result1)</span>
    <span class=n>result2</span> <span class=o>=</span> <span class=n>soup1</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=n>attrs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;class&#34;</span><span class=p>:</span><span class=s2>&#34;buyer-feedback&#34;</span><span class=p>})</span>
    <span class=n>result2</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>result2</span><span class=p>)</span>

    <span class=n>soup2</span> <span class=o>=</span> <span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>result2</span><span class=p>,</span><span class=s1>&#39;lxml&#39;</span><span class=p>)</span>
    <span class=n>result3</span> <span class=o>=</span> <span class=n>soup2</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=s1>&#39;span&#39;</span><span class=p>)</span>


    <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>10</span><span class=p>):</span>
        <span class=n>commentTime</span> <span class=o>=</span> <span class=n>result1</span><span class=p>[</span><span class=n>j</span><span class=p>]</span><span class=o>.</span><span class=n>string</span>
        <span class=k>print</span><span class=p>(</span><span class=n>commentTime</span><span class=p>)</span>
        <span class=n>commentContent</span> <span class=o>=</span> <span class=n>result3</span><span class=p>[</span><span class=n>j</span><span class=p>]</span><span class=o>.</span><span class=n>get_text</span><span class=p>()</span>
        <span class=k>print</span><span class=p>(</span><span class=n>commentContent</span><span class=p>)</span>


        <span class=s1>&#39;&#39;&#39;
</span><span class=s1>        数据库操作
</span><span class=s1>        &#39;&#39;&#39;</span>



        <span class=c1>#获取数据库链接</span>
        <span class=n>connection</span>  <span class=o>=</span> <span class=n>pymysql</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=n>host</span> <span class=o>=</span> <span class=s1>&#39;localhost&#39;</span><span class=p>,</span>
                                  <span class=n>user</span> <span class=o>=</span> <span class=s1>&#39;root&#39;</span><span class=p>,</span>
                                  <span class=n>password</span> <span class=o>=</span> <span class=s1>&#39;123456&#39;</span><span class=p>,</span>
                                  <span class=n>db</span> <span class=o>=</span> <span class=s1>&#39;comment&#39;</span><span class=p>,</span>
                                  <span class=n>charset</span> <span class=o>=</span> <span class=s1>&#39;utf8mb4&#39;</span><span class=p>)</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=c1>#获取会话指针</span>
            <span class=k>with</span> <span class=n>connection</span><span class=o>.</span><span class=n>cursor</span><span class=p>()</span> <span class=k>as</span> <span class=n>cursor</span><span class=p>:</span>
                <span class=c1>#创建sql语句</span>
                <span class=n>sql</span> <span class=o>=</span> <span class=s2>&#34;insert into `agm` (`commentTime`,`commentContent`) values (</span><span class=si>%s</span><span class=s2>,</span><span class=si>%s</span><span class=s2>)&#34;</span>

                <span class=c1>#执行sql语句</span>
                <span class=n>cursor</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>sql</span><span class=p>,(</span><span class=n>commentTime</span><span class=p>,</span><span class=n>commentContent</span><span class=p>))</span>

                <span class=c1>#提交数据库</span>
                <span class=n>connection</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
        <span class=k>finally</span><span class=p>:</span>
            <span class=n>connection</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>



<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>26</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;正在下载第{}页数据...&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>))</span>
    <span class=c1>#速卖通商品评论链接</span>
    <span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://feedback.aliexpress.com/display/productEvaluation.htm?productId=32789025522&amp;ownerMemberId=224795258&amp;companyId=234539103&amp;memberType=seller&amp;startValidDate=&amp;i18n=true&amp;page=&#34;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
    <span class=n>crawl</span><span class=p>(</span><span class=n>url</span><span class=p>,</span><span class=n>i</span><span class=p>)</span>
    <span class=n>t</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>11</span><span class=p>,</span><span class=mi>16</span><span class=p>)</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;休眠时间为:{}s&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>t</span><span class=p>))</span>
    <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=n>t</span><span class=p>)</span>

</code></pre></td></tr></table></div></div><p><strong>(2) 获取到的数据格式如下所示：</strong></p><p><img src=./images/20170815171139994.gif alt=image></p><h3 id=用wordart做词频分析>用WordArt做词频分析</h3><p>首先选取20个用户的评论数据导入WordArt中，删除部分无用字符之后的初步分析结果如下图所示：</p><p><img src=./images/20170815172658494.gif alt=image></p><p>设置好图片的形状、字体、布局等参数之后，画出来的效果如下图所示：</p><p><img src=./images/20170815172718392.gif alt=image></p><p>通过上图，可以很直观地看出评论中哪些词语出现的频率最高。</p><h2 id=六基于lda的文章主题生成>六、基于LDA的文章主题生成</h2><h3 id=lda概述>LDA概述</h3><p><strong>LDA（Latent Dirichlet Allocation）<strong>是一种</strong>文档主题生成模型</strong>，也称为一个<strong>三层贝叶斯概率模型</strong>，包含<strong>词</strong>、<strong>主题</strong>和<strong>文档</strong>三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“<strong>以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语</strong>”这样一个过程得到。<strong>文档到主题服从多项式分布，主题到词服从多项式分布</strong>。</p><p><strong>LDA</strong>是一种<strong>非监督机器学习技术</strong>，可以用来<strong>识别大规模文档集</strong>（document collection）或<strong>语料库</strong>（corpus）中<strong>潜藏的主题信息</strong>。它采用了<strong>词袋</strong>（bag of words）的方法，这种方法<strong>将每一篇文档视为一个词频向量</strong>，从而将<strong>文本信息</strong>转化为了易于建模的<strong>数字信息</strong>。<strong>每一篇文档代表了一些主题所构成的一个概率分布，而每一个主题又代表了很多单词所构成的一个概率分布</strong>。</p><p><strong>LDA模型</strong>的<strong>推导过程</strong>包括<strong>多项式分布</strong>、<strong>Dirichlet分布</strong>和<strong>Gibbs抽样</strong>等。具体来说，主要在以下几个方面有广泛的应用：
（1）通过<strong>Dirichlet分布取样</strong>获得<strong>生成文档的主题分布</strong>和<strong>生成主题的词语分布</strong>。
（2）通过<strong>主题的多项式分布取样</strong>，得到<strong>当前文档的对应词语的主题</strong>。
（3）通过<strong>词语的多项式分布采样</strong>，得到<strong>生成的词语</strong>。</p><h3 id=基于lda的文章主题生成>基于LDA的文章主题生成</h3><p>本文使用python下的<strong>lda库</strong>来<strong>获取语料库</strong>和<strong>计算文章主题</strong>。</p><p><strong>实现代码如下所示：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Sun Aug 27 20:51:15 2017
</span><span class=s2>
</span><span class=s2>@author: Administrator
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>numpy</span> <span class=kn>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>lda</span>
<span class=kn>import</span> <span class=nn>lda.datasets</span>

<span class=s1>&#39;&#39;&#39;
</span><span class=s1>1.导入数据源
</span><span class=s1>&#39;&#39;&#39;</span>
<span class=c1>#通过LDA库自带的API接口调用路透社的数据</span>
<span class=n>titles</span> <span class=o>=</span> <span class=n>lda</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>load_reuters_titles</span><span class=p>()</span>

<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>395</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>


<span class=s1>&#39;&#39;&#39;
</span><span class=s1>2.求解P(词语|主题),得到每个主题所包含的单词的分布
</span><span class=s1>&#39;&#39;&#39;</span>
<span class=n>X</span> <span class=o>=</span> <span class=n>lda</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>load_reuters</span><span class=p>()</span>
<span class=n>vocab</span> <span class=o>=</span> <span class=n>lda</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>load_reuters_vocab</span><span class=p>()</span>
<span class=n>titles</span> <span class=o>=</span> <span class=n>lda</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>load_reuters_titles</span><span class=p>()</span>
<span class=c1>#设置主题数目为20个，每个主题包含8个词语，模型迭代次数为1500次</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>lda</span><span class=o>.</span><span class=n>LDA</span><span class=p>(</span><span class=n>n_topics</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span><span class=n>n_iter</span><span class=o>=</span><span class=mi>1500</span><span class=p>,</span><span class=n>random_state</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
<span class=n>topic_word</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>topic_word_</span>
<span class=n>n_top_words</span> <span class=o>=</span> <span class=mi>8</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span><span class=n>topic_dist</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>topic_word</span><span class=p>):</span>
    <span class=n>topic_words</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>vocab</span><span class=p>)[</span><span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>topic_dist</span><span class=p>)][:</span><span class=o>-</span><span class=p>(</span><span class=n>n_top_words</span><span class=o>+</span><span class=mi>1</span><span class=p>):</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
    <span class=c1>#输出每个主题所包含的单词的分布</span>
    <span class=k>print</span><span class=p>(</span><span class=s1>&#39;Topic{}:{}&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>,</span><span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>topic_words</span><span class=p>)))</span>

<span class=s1>&#39;&#39;&#39;
</span><span class=s1>3.求解P(主题|文档),得到文章所对应的主题
</span><span class=s1>&#39;&#39;&#39;</span>
<span class=n>doc_topic</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>doc_topic_</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>20</span><span class=p>):</span>
    <span class=c1>#输出文章所对应的主题</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;{} (top topic:{})&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>doc_topic</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>argmax</span><span class=p>()))</span>

</code></pre></td></tr></table></div></div><p><strong>运行结果如下图所示：</strong></p><p><img src=./images/20170827214405712.gif alt=image></p><p>由上图可知，调用的<strong>数据集文章数为395</strong>，<strong>文章单词个数为84010</strong>，<strong>文章主题数为20个</strong>。<strong>部分文章的标题如下图所示：</strong></p><p><img src=./images/20170827215039954.gif alt=image></p><p><strong>每个主题所包含的单词的分布如下图所示：</strong></p><p><img src=./images/20170827215141128.gif alt=image></p><p><strong>文章所对应的主题如下图所示（部分，取前20篇文章）：</strong></p><p><img src=./images/20170827215451877.gif alt=image></p><h2 id=七基于tf-idf的文本自动打标>七、基于TF-IDF的文本自动打标</h2><h3 id=tf-idf简介>TF-IDF简介</h3><p><strong>TF-IDF</strong>（Term Frequency-Inverse Document Frequency）是一种统计方法，<strong>用以评估某一字词对于一个文件集或一个语料库中的其中一份文件的重要程度</strong>。字词的重要性<strong>随着它在文件中出现的次数成正比增加</strong>，但同时会<strong>随着它在语料库中出现的频率成反比下降</strong>。<strong>TF-IDF倾向于过滤掉常见的词语，保留重要的词语</strong>。TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。在本文中，主要用TF-IDF来实现文本自动打标。</p><h3 id=应用案例>应用案例</h3><p><strong>（1）应用案例1：找出文章最具代表性的词</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Thu Aug 31 22:48:55 2017
</span><span class=s2>
</span><span class=s2>@author: Administrator
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>log</span>


<span class=c1>#tf计算</span>
<span class=k>def</span> <span class=nf>tf</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>doc</span><span class=p>):</span>
    <span class=n>all_num</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([</span><span class=n>doc</span><span class=p>[</span><span class=n>key</span><span class=p>]</span> <span class=k>for</span> <span class=n>key</span> <span class=ow>in</span> <span class=n>doc</span><span class=p>])</span>
    <span class=k>return</span> <span class=nb>float</span><span class=p>(</span><span class=n>doc</span><span class=p>[</span><span class=n>word</span><span class=p>])</span> <span class=o>/</span> <span class=n>all_num</span>

<span class=c1>#idf计算</span>
<span class=k>def</span> <span class=nf>idf</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>doc_list</span><span class=p>):</span>
    <span class=n>all_num</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>doc_list</span><span class=p>)</span>
    <span class=n>word_count</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>doc_list</span><span class=p>:</span>
        <span class=k>if</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>doc</span><span class=p>:</span>
            <span class=n>word_count</span> <span class=o>+=</span> <span class=mi>1</span>
    <span class=k>return</span> <span class=n>log</span><span class=p>(</span><span class=n>all_num</span><span class=o>/</span><span class=n>word_count</span><span class=p>)</span>

<span class=c1>#tfdif计算(tfidf = tf * idf)</span>
<span class=k>def</span> <span class=nf>tfidf</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>doc</span><span class=p>,</span><span class=n>doc_list</span><span class=p>):</span>
    <span class=n>score</span> <span class=o>=</span> <span class=n>tf</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>doc</span><span class=p>)</span><span class=o>*</span><span class=n>idf</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>doc_list</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>score</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>

    <span class=n>doc1</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;at&#39;</span><span class=p>:</span><span class=mi>16</span><span class=p>,</span><span class=s1>&#39;tell&#39;</span><span class=p>:</span><span class=mi>132</span><span class=p>,</span><span class=s1>&#39;soft&#39;</span><span class=p>:</span><span class=mi>42</span><span class=p>,</span><span class=s1>&#39;let&#39;</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=s1>&#39;this&#39;</span><span class=p>:</span><span class=mi>32</span><span class=p>}</span>
    <span class=n>doc2</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;tell&#39;</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=s1>&#39;be&#39;</span><span class=p>:</span><span class=mi>46</span><span class=p>,</span><span class=s1>&#39;tea&#39;</span><span class=p>:</span><span class=mi>43</span><span class=p>,</span><span class=s1>&#39;what&#39;</span><span class=p>:</span><span class=mi>46</span><span class=p>,</span><span class=s1>&#39;foot&#39;</span><span class=p>:</span><span class=mi>65</span><span class=p>,</span><span class=s1>&#39;hack&#39;</span><span class=p>:</span><span class=mi>32</span><span class=p>}</span>
    <span class=n>doc3</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;soft&#39;</span><span class=p>:</span><span class=mi>65</span><span class=p>,</span><span class=s1>&#39;this&#39;</span><span class=p>:</span><span class=mi>67</span><span class=p>,</span><span class=s1>&#39;tell&#39;</span><span class=p>:</span><span class=mi>78</span><span class=p>,</span><span class=s1>&#39;how&#39;</span><span class=p>:</span><span class=mi>124</span><span class=p>,</span><span class=s1>&#39;foot&#39;</span><span class=p>:</span><span class=mi>54</span><span class=p>}</span>

    <span class=n>doc_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>doc1</span><span class=p>,</span><span class=n>doc2</span><span class=p>,</span><span class=n>doc3</span><span class=p>]</span>
    <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span>
    <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>doc_list</span><span class=p>:</span>
        <span class=k>print</span><span class=p>(</span><span class=s1>&#39;-&#39;</span><span class=o>*</span><span class=mi>30</span><span class=p>)</span>
        <span class=k>print</span><span class=p>(</span><span class=s2>&#34;doc{}中各单词的tfidf值:&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>))</span>
        <span class=c1>#循环输出每个文档中每个单词的tfidf值</span>
        <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>doc</span><span class=p>:</span>
            <span class=k>print</span><span class=p>(</span><span class=s1>&#39;&#34;{}&#34;:{}&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>tfidf</span><span class=p>(</span><span class=n>word</span><span class=p>,</span><span class=n>doc</span><span class=p>,</span><span class=n>doc_list</span><span class=p>)))</span>
        <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>

</code></pre></td></tr></table></div></div><p><strong>运行结果如下图所示：</strong></p><p><img src=./images/20170831231413434.gif alt=image></p><p>根据上图中各文档中各个单词的tfidf值大小可以选出doc1、doc2、doc3三个文档中最具代表性的单词分别为:”let”,”be”,”how”。当然，上述案例只是tfidf应用的简单示例，后面会进一步介绍tfidf在实际业务中的应用。</p><h2 id=八textrank>八、TextRank</h2><p>TextRank是自然语言处理领域一种比较常见的关键词提取算法，可用于提取关键词、短语和自动生成文本摘要。TextRank是由PageRank算法改进过来的，所以有大量借鉴PageRank的思想，其处理文本数据的过程主要包括以下几个步骤：</p><p>（1）首先，将原文本拆分为句子，在每个句子中过滤掉停用词（可以不选），并只保留指定词性的单词，由此可以得到句子和单词的集合。</p><p>（2）每个单词作为PageRank中的一个节点。设窗口大小为k，假设一个句子所组成的单词可以表示为w1,w2,w3,…, wn.</p><p>则w1,w2, …, wk、w2,w3,…,wk+1、w3,w4,…,wk+2等都是一个窗口，在一个窗口内任意两个单词之间存在一条无向无权的边。</p><p>（3）基于上面的节点和边构成图，可以据此计算出每个节点的重要性。最重要的若干单词可以作为区分文本类别和主题的关键词。</p><p>基于荣耀V10手机评论数据的Python代码实现如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=s2>&#34;&#34;&#34;
</span><span class=s2>Created on Fri Feb  9 15:58:14 2018
</span><span class=s2>@author: zch
</span><span class=s2>&#34;&#34;&#34;</span>

<span class=kn>import</span> <span class=nn>codecs</span>
<span class=kn>from</span> <span class=nn>textrank4zh</span> <span class=kn>import</span> <span class=n>TextRank4Keyword</span><span class=p>,</span> <span class=n>TextRank4Sentence</span>

<span class=c1>#读取华为荣耀天猫旗舰店荣耀V10手机的评论文本数据</span>
<span class=n>text</span> <span class=o>=</span> <span class=n>codecs</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s1>&#39;D://data/tmall/origin_tmall_review.txt&#39;</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=s1>&#39;utf-8&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>

<span class=n>tr4w</span> <span class=o>=</span> <span class=n>TextRank4Keyword</span><span class=p>()</span>

<span class=n>tr4w</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>text</span><span class=p>,</span> <span class=n>lower</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>window</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>

<span class=k>print</span><span class=p>(</span> <span class=s1>&#39;关键词：&#39;</span> <span class=p>)</span>
<span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>tr4w</span><span class=o>.</span><span class=n>get_keywords</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=n>word_min_len</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;{} 出现的频率为:{:.6f}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>item</span><span class=o>.</span><span class=n>word</span><span class=p>,</span> <span class=n>item</span><span class=o>.</span><span class=n>weight</span><span class=p>))</span>
    
<span class=k>print</span><span class=p>(</span> <span class=s1>&#39;关键短语：&#39;</span> <span class=p>)</span>
<span class=k>for</span> <span class=n>phrase</span> <span class=ow>in</span> <span class=n>tr4w</span><span class=o>.</span><span class=n>get_keyphrases</span><span class=p>(</span><span class=n>keywords_num</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>min_occur_num</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
    <span class=k>print</span><span class=p>(</span><span class=n>phrase</span><span class=p>)</span>
<span class=n>tr4s</span> <span class=o>=</span> <span class=n>TextRank4Sentence</span><span class=p>()</span>
<span class=n>tr4s</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>text</span><span class=p>,</span> <span class=n>lower</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>source</span> <span class=o>=</span> <span class=s1>&#39;all_filters&#39;</span><span class=p>)</span>

<span class=k>print</span><span class=p>()</span>
<span class=k>print</span><span class=p>(</span> <span class=s1>&#39;摘要：&#39;</span> <span class=p>)</span>
<span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>tr4s</span><span class=o>.</span><span class=n>get_key_sentences</span><span class=p>(</span><span class=n>num</span><span class=o>=</span><span class=mi>3</span><span class=p>):</span>
    <span class=c1>#index是语句在文本中位置，weight是权重</span>
    <span class=k>print</span><span class=p>(</span><span class=s2>&#34;第{}句出现的频率为:{:.6f},内容为:{}&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>item</span><span class=o>.</span><span class=n>index</span><span class=p>,</span> <span class=n>item</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>item</span><span class=o>.</span><span class=n>sentence</span><span class=p>))</span>

</code></pre></td></tr></table></div></div><p>输出的关键词如下图所示：</p><p><img src=./images/20180209172240492.png alt=image></p><p>输出的关键短语如下图所示：</p><p><img src=./images/2018020917230441.png alt=image></p><p>输出的摘要如下图所示：</p><p><img src=./images/20180209172328367.png alt=image></p><p>从上面的输出结果可以看出，华为荣耀V10的评论信息，大多数还是比较积极、正面的，能够基本反映出用户对这款手机产品的态度。</p><p>&mdash;EOF&mdash;</p><p><em>EOF</em>是一个计算机术语，为<code>End Of File</code>的缩写，在操作系统中表示资料源无更多的资料可读取。通常在文本的最后存在此字符表示资料结束。</p><p>本人公众号<code>火山灰</code>，亦可搜<code>time_ash_past</code>。</p><p><img src=https://raw.githubusercontent.com/sanbeichahegongheguo/sanbeichahegongheguo.github.io/master/%E5%85%AC%E4%BC%97%E5%8F%B7.jpg alt></p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>总舵主</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>0001-01-01</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/wechat-pay.jpg>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/pulic.jpg>
<span>公众号</span></label></div></div><footer class=post-footer><div class=post-tags><a href=/tags/%E7%BC%96%E7%A8%8B/>编程</a>
<a href=/tags/nlp/>NLP</a>
<a href=/tags/%E5%85%A5%E9%97%A8/>入门</a>
<a href=/tags/%E8%BD%AC%E8%BD%BD/>转载</a>
<a href=/tags/python/>python</a></div><nav class=post-nav><a class=prev href=/post/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%85%A5%E9%97%A8/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">转载 | 版本控制系统入门</span>
<span class="prev-text nav-mobile">上一篇</span></a></nav></footer></article><div class=related-content><h4>相关阅读</h4><ul class=article-gallery><p><a href=/post/%E8%81%8A%E4%B8%80%E4%B8%AA%E7%AE%97%E6%B3%95%E5%85%A5%E9%97%A8%E9%A2%98/>聊一个算法入门题</a></p><p><a href=/post/%E6%88%91%E6%9C%89%E4%B8%AA%E6%A2%A6%E4%B8%8D%E6%83%B3%E9%86%92/>转载 | 我有个梦，不想醒</a></p><p><a href=/post/%E8%BD%AC%E8%BD%BD-linux-%E7%B3%BB%E7%BB%9F%E5%92%8C-shell-%E7%BC%96%E7%A8%8B%E9%97%AE%E9%A2%98%E9%9B%86/>转载 | Linux 系统和 Shell 编程问题集</a></p><p><a href=/post/anaconda%E5%85%A5%E9%97%A8/>Anaconda入门</a></p><p><a href=/post/zotero%E5%85%A5%E9%97%A8/>Zotero入门</a></p><p><a href=/post/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%85%A5%E9%97%A8/>转载 | 版本控制系统入门</a></p></ul><div class="post bg-white"><script src=https://utteranc.es/client.js repo=sanbeichahegongheguo/sanbeichahegongheguo.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2017 -
2021
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>总舵主</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.dee43230127a73d039a734510fa896c89c3c7ce0cf0be0c7a7433f8fd69b76dc.js integrity="sha256-3uQyMBJ6c9A5pzRRD6iWyJw8fODPC+DHp0M/j9abdtw=" crossorigin=anonymous></script><script type=text/javascript>window.MathJax={showProcessingMessages:!1,messageStyle:'none'}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css integrity=sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js integrity=sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{})})</script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>